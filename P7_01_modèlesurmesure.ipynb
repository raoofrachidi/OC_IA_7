{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40452613",
   "metadata": {},
   "source": [
    "# Sommaire\n",
    "\n",
    "* [I. Pré-traitement des données](#I)\n",
    "* [II. Entraînement du modèle](#II)\n",
    "* [III. Connection à l'espace Azure](#III)\n",
    "* [IV. Enregistrement du modèle](#IV)\n",
    "* [V. Déploiement du modèle](#V)\n",
    "* [VI. Utilisation du web service](#VI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "601986ca",
   "metadata": {
    "gather": {
     "logged": 1644961686092
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.1.0\n",
      "Using GPU build: True\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Math libraries to process the data \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# Libraries for preprocessing \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Classification libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Embedding,\n",
    "    Dropout,\n",
    "    LSTM,\n",
    "    GlobalMaxPool1D,\n",
    "    Bidirectional,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from tensorflow.keras import backend as K\n",
    "import azureml.core\n",
    "from azureml.core import Experiment, Workspace, Environment\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.environment import CondaDependencies\n",
    "from azureml.core import Webservice\n",
    "import pickle\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "print(\"Tensorflow version:\", tensorflow.__version__)\n",
    "print(\"Using GPU build:\", tensorflow.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b710265e",
   "metadata": {},
   "source": [
    "## I. Pré-traitement des données<a class=\"anchor\" id=\"I\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "035ff68e",
   "metadata": {
    "gather": {
     "logged": 1644961693225
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/azureuser/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "100%|██████████| 5298/5298 [00:00<00:00, 553184.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Word index length:  5299\n",
      "Converted words: 3920, missing words: 1378\n",
      "% of missing words: 26.0%\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "# Download dataset\n",
    "dataframe_sample = pd.read_csv(\"data/dataframe_sample.csv\", index_col=[0])\n",
    "dataframe_sample = dataframe_sample.drop(columns=[\"Unnamed: 1\", \"target.1\"], axis=1)\n",
    "\n",
    "# Normalize target\n",
    "dataframe_sample['target'] = dataframe_sample['target'] / 4\n",
    "\n",
    "# Transform target from float to integer\n",
    "dataframe_sample['target'] = dataframe_sample['target'].apply(lambda x: int(x))\n",
    "\n",
    "# Vectorize (convert words to numbers) with Keras tokenizer\n",
    "tk = Tokenizer(num_words=None)\n",
    "tk.fit_on_texts(dataframe_sample.text)\n",
    "\n",
    "def embed(corpus): \n",
    "    return word_tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "# Set text values\n",
    "text_values = dataframe_sample.text.values\n",
    "\n",
    "# Get longest sentence length\n",
    "longest_train = max(text_values, key=lambda sentence: len(word_tokenize(sentence)))\n",
    "length_long_sentence = len(word_tokenize(longest_train))\n",
    "\n",
    "# Vectorize (convert words to numbers) with Keras tokenizer\n",
    "word_tokenizer = Tokenizer()\n",
    "word_tokenizer.fit_on_texts(text_values)\n",
    "\n",
    "# Get the dictionary of vocab created by Keras\n",
    "word_index = tk.word_index\n",
    "\n",
    "# Transform in fixed length structure\n",
    "padded_sentences = pad_sequences(embed(text_values), length_long_sentence, padding='post')\n",
    "\n",
    "# Set target values\n",
    "sentiments = dataframe_sample.target.values\n",
    "\n",
    "# Split the data in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    padded_sentences, \n",
    "    sentiments, \n",
    "    test_size=0.3\n",
    ")\n",
    "\n",
    "# Define path variable\n",
    "glove_path = 'data/glove.6B.50d.txt'\n",
    "\n",
    "# Load GloVe vectors in a dictionary\n",
    "embeddings_index = {}\n",
    "\n",
    "glove = open(glove_path, 'r', encoding='utf-8')\n",
    "for line in glove:\n",
    "    values = line.split(' ')\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = vector\n",
    "glove.close()\n",
    "\n",
    "# Number of dimension of GloVe word embedding \n",
    "GLOVE_DIM = 50\n",
    "\n",
    "# Create embedding matrix for word in train set\n",
    "embeddings_matrix_glove = np.zeros((len(word_index) + 1, GLOVE_DIM))\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    # Check if the word occurs in Glove embedding\n",
    "    embeddings_vector = embeddings_index.get(word)\n",
    "    if embeddings_vector is not None:\n",
    "        # If not, keep the vector with zeros only\n",
    "        embeddings_matrix_glove[i] = embeddings_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "\n",
    "print('\\n')\n",
    "print('Word index length: ', len(word_index) + 1)\n",
    "print('Converted words: {}, missing words: {}'.format(hits, misses))\n",
    "print('% of missing words: {:.1f}%'.format(misses / (hits + misses)*100))\n",
    "\n",
    "# Define model constants\n",
    "epochs = 50\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32afe886",
   "metadata": {},
   "source": [
    "## II. Entraînement du modèle<a class=\"anchor\" id=\"II\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "954fab38",
   "metadata": {
    "gather": {
     "logged": 1644961713364
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"glove_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 46, 50)            264950    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 46, 92)            35696     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 92)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 92)                368       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 92)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 46)                4278      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 46)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 46)                2162      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 46)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 47        \n",
      "=================================================================\n",
      "Total params: 307,501\n",
      "Trainable params: 307,317\n",
      "Non-trainable params: 184\n",
      "_________________________________________________________________\n",
      "Train on 784 samples, validate on 336 samples\n",
      "Epoch 1/50\n",
      "784/784 [==============================] - 4s 5ms/sample - loss: 1.0870 - recall: 0.2949 - precision: 0.4694 - val_loss: 0.6935 - val_recall: 0.2775 - val_precision: 0.5053\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/50\n",
      "784/784 [==============================] - 0s 391us/sample - loss: 0.9785 - recall: 0.3769 - precision: 0.5000 - val_loss: 0.6912 - val_recall: 0.4855 - val_precision: 0.5638\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/50\n",
      "784/784 [==============================] - 0s 378us/sample - loss: 0.8849 - recall: 0.4718 - precision: 0.5125 - val_loss: 0.6896 - val_recall: 0.6647 - val_precision: 0.5721\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/50\n",
      "784/784 [==============================] - 0s 381us/sample - loss: 0.8848 - recall: 0.5231 - precision: 0.5025 - val_loss: 0.6887 - val_recall: 0.7399 - val_precision: 0.5565\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/50\n",
      "784/784 [==============================] - 0s 383us/sample - loss: 0.8618 - recall: 0.5795 - precision: 0.5195 - val_loss: 0.6883 - val_recall: 0.7225 - val_precision: 0.5656\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/50\n",
      "784/784 [==============================] - 0s 379us/sample - loss: 0.7751 - recall: 0.5872 - precision: 0.5350 - val_loss: 0.6884 - val_recall: 0.6936 - val_precision: 0.5687\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/50\n",
      "784/784 [==============================] - 0s 382us/sample - loss: 0.8166 - recall: 0.5846 - precision: 0.5352 - val_loss: 0.6885 - val_recall: 0.6705 - val_precision: 0.5659\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/50\n",
      "784/784 [==============================] - 0s 381us/sample - loss: 0.7956 - recall: 0.6231 - precision: 0.5561 - val_loss: 0.6884 - val_recall: 0.6936 - val_precision: 0.5687\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/50\n",
      "784/784 [==============================] - 0s 382us/sample - loss: 0.8204 - recall: 0.5744 - precision: 0.5271 - val_loss: 0.6884 - val_recall: 0.6705 - val_precision: 0.6073\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/50\n",
      "784/784 [==============================] - 0s 433us/sample - loss: 0.7705 - recall: 0.6026 - precision: 0.5516 - val_loss: 0.6886 - val_recall: 0.6185 - val_precision: 0.6011\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/50\n",
      "784/784 [==============================] - 0s 374us/sample - loss: 0.7479 - recall: 0.5564 - precision: 0.5332 - val_loss: 0.6889 - val_recall: 0.5780 - val_precision: 0.6061\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/50\n",
      "784/784 [==============================] - 0s 381us/sample - loss: 0.7655 - recall: 0.5333 - precision: 0.5226 - val_loss: 0.6892 - val_recall: 0.5376 - val_precision: 0.6159\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/50\n",
      "784/784 [==============================] - 0s 379us/sample - loss: 0.7617 - recall: 0.5590 - precision: 0.5662 - val_loss: 0.6894 - val_recall: 0.5318 - val_precision: 0.6345\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/50\n",
      "784/784 [==============================] - 0s 361us/sample - loss: 0.7379 - recall: 0.5564 - precision: 0.5636 - val_loss: 0.6896 - val_recall: 0.4913 - val_precision: 0.6204\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/50\n",
      "784/784 [==============================] - 0s 369us/sample - loss: 0.7476 - recall: 0.5308 - precision: 0.5476 - val_loss: 0.6898 - val_recall: 0.5029 - val_precision: 0.6214\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/50\n",
      "784/784 [==============================] - 0s 385us/sample - loss: 0.7354 - recall: 0.5205 - precision: 0.5670 - val_loss: 0.6899 - val_recall: 0.5087 - val_precision: 0.5986\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 17/50\n",
      "784/784 [==============================] - 0s 373us/sample - loss: 0.7317 - recall: 0.5590 - precision: 0.5464 - val_loss: 0.6899 - val_recall: 0.5780 - val_precision: 0.6173\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 18/50\n",
      "784/784 [==============================] - 0s 371us/sample - loss: 0.7019 - recall: 0.5692 - precision: 0.5952 - val_loss: 0.6901 - val_recall: 0.6705 - val_precision: 0.5918\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 19/50\n",
      "784/784 [==============================] - 0s 388us/sample - loss: 0.7136 - recall: 0.5897 - precision: 0.5808 - val_loss: 0.6904 - val_recall: 0.7572 - val_precision: 0.5746\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 20/50\n",
      "784/784 [==============================] - 0s 376us/sample - loss: 0.7186 - recall: 0.5692 - precision: 0.5564 - val_loss: 0.6904 - val_recall: 0.7919 - val_precision: 0.5756\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 21/50\n",
      "784/784 [==============================] - 0s 413us/sample - loss: 0.7012 - recall: 0.6128 - precision: 0.5858 - val_loss: 0.6902 - val_recall: 0.7746 - val_precision: 0.5726\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 22/50\n",
      "784/784 [==============================] - 0s 359us/sample - loss: 0.6902 - recall: 0.6231 - precision: 0.5941 - val_loss: 0.6897 - val_recall: 0.7514 - val_precision: 0.6019\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 23/50\n",
      "784/784 [==============================] - 0s 392us/sample - loss: 0.6917 - recall: 0.5718 - precision: 0.5533 - val_loss: 0.6890 - val_recall: 0.7052 - val_precision: 0.6162\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 24/50\n",
      "784/784 [==============================] - 0s 374us/sample - loss: 0.6684 - recall: 0.6231 - precision: 0.6152 - val_loss: 0.6884 - val_recall: 0.6532 - val_precision: 0.6420\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 25/50\n",
      "784/784 [==============================] - 0s 375us/sample - loss: 0.6368 - recall: 0.6359 - precision: 0.5990 - val_loss: 0.6878 - val_recall: 0.6474 - val_precision: 0.6788\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 26/50\n",
      "784/784 [==============================] - 0s 391us/sample - loss: 0.6716 - recall: 0.5821 - precision: 0.5821 - val_loss: 0.6871 - val_recall: 0.6416 - val_precision: 0.6938\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 27/50\n",
      "784/784 [==============================] - 0s 376us/sample - loss: 0.6693 - recall: 0.6282 - precision: 0.6171 - val_loss: 0.6864 - val_recall: 0.6301 - val_precision: 0.6943\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 28/50\n",
      "784/784 [==============================] - 0s 391us/sample - loss: 0.6563 - recall: 0.6154 - precision: 0.6138 - val_loss: 0.6856 - val_recall: 0.6185 - val_precision: 0.7039\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 29/50\n",
      "784/784 [==============================] - 0s 384us/sample - loss: 0.6496 - recall: 0.6462 - precision: 0.6316 - val_loss: 0.6846 - val_recall: 0.5549 - val_precision: 0.6906\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 30/50\n",
      "784/784 [==============================] - 0s 365us/sample - loss: 0.6263 - recall: 0.6359 - precision: 0.6294 - val_loss: 0.6835 - val_recall: 0.5145 - val_precision: 0.6953\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 31/50\n",
      "784/784 [==============================] - 0s 366us/sample - loss: 0.6027 - recall: 0.6641 - precision: 0.6395 - val_loss: 0.6825 - val_recall: 0.5202 - val_precision: 0.7031\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 32/50\n",
      "784/784 [==============================] - 0s 420us/sample - loss: 0.6193 - recall: 0.6692 - precision: 0.6460 - val_loss: 0.6814 - val_recall: 0.5723 - val_precision: 0.6972\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 33/50\n",
      "784/784 [==============================] - 0s 380us/sample - loss: 0.5959 - recall: 0.6718 - precision: 0.6650 - val_loss: 0.6801 - val_recall: 0.5838 - val_precision: 0.7113\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 34/50\n",
      "784/784 [==============================] - 0s 371us/sample - loss: 0.5805 - recall: 0.6615 - precision: 0.7030 - val_loss: 0.6779 - val_recall: 0.5896 - val_precision: 0.7034\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 35/50\n",
      "784/784 [==============================] - 0s 374us/sample - loss: 0.6148 - recall: 0.6487 - precision: 0.6521 - val_loss: 0.6759 - val_recall: 0.5954 - val_precision: 0.6959\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 36/50\n",
      "784/784 [==============================] - 0s 387us/sample - loss: 0.6060 - recall: 0.6590 - precision: 0.6710 - val_loss: 0.6747 - val_recall: 0.6301 - val_precision: 0.6943\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 37/50\n",
      "784/784 [==============================] - 0s 370us/sample - loss: 0.5595 - recall: 0.7282 - precision: 0.7154 - val_loss: 0.6736 - val_recall: 0.6358 - val_precision: 0.6875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 38/50\n",
      "784/784 [==============================] - 0s 372us/sample - loss: 0.5540 - recall: 0.6795 - precision: 0.7067 - val_loss: 0.6718 - val_recall: 0.6301 - val_precision: 0.6943\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 39/50\n",
      "784/784 [==============================] - 0s 395us/sample - loss: 0.5492 - recall: 0.7256 - precision: 0.7165 - val_loss: 0.6700 - val_recall: 0.6301 - val_precision: 0.6943\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 40/50\n",
      "784/784 [==============================] - 0s 397us/sample - loss: 0.5186 - recall: 0.7179 - precision: 0.7447 - val_loss: 0.6676 - val_recall: 0.6358 - val_precision: 0.6918\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 41/50\n",
      "784/784 [==============================] - 0s 381us/sample - loss: 0.5264 - recall: 0.7564 - precision: 0.7195 - val_loss: 0.6649 - val_recall: 0.6474 - val_precision: 0.6871\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 42/50\n",
      "784/784 [==============================] - 0s 387us/sample - loss: 0.5059 - recall: 0.7846 - precision: 0.7463 - val_loss: 0.6623 - val_recall: 0.6474 - val_precision: 0.6788\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 43/50\n",
      "784/784 [==============================] - 0s 428us/sample - loss: 0.4758 - recall: 0.8179 - precision: 0.7595 - val_loss: 0.6594 - val_recall: 0.6416 - val_precision: 0.6768\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 44/50\n",
      "784/784 [==============================] - 0s 376us/sample - loss: 0.4620 - recall: 0.7872 - precision: 0.7637 - val_loss: 0.6569 - val_recall: 0.6474 - val_precision: 0.6667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 45/50\n",
      "784/784 [==============================] - 0s 384us/sample - loss: 0.4700 - recall: 0.8051 - precision: 0.7811 - val_loss: 0.6539 - val_recall: 0.6358 - val_precision: 0.6707\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 46/50\n",
      "784/784 [==============================] - 0s 398us/sample - loss: 0.4532 - recall: 0.8000 - precision: 0.7723 - val_loss: 0.6497 - val_recall: 0.6069 - val_precision: 0.6954\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 47/50\n",
      "784/784 [==============================] - 0s 373us/sample - loss: 0.4542 - recall: 0.7974 - precision: 0.8078 - val_loss: 0.6456 - val_recall: 0.6069 - val_precision: 0.7241\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 48/50\n",
      "784/784 [==============================] - 0s 379us/sample - loss: 0.4303 - recall: 0.7795 - precision: 0.8064 - val_loss: 0.6415 - val_recall: 0.6358 - val_precision: 0.6875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 49/50\n",
      "784/784 [==============================] - 0s 382us/sample - loss: 0.4029 - recall: 0.7897 - precision: 0.8127 - val_loss: 0.6381 - val_recall: 0.6821 - val_precision: 0.6705\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 50/50\n",
      "784/784 [==============================] - 0s 394us/sample - loss: 0.3763 - recall: 0.8333 - precision: 0.8355 - val_loss: 0.6329 - val_recall: 0.6647 - val_precision: 0.6647\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "480/480 [==============================] - 0s 122us/sample - loss: 0.6284 - recall: 0.7342 - precision: 0.6797\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Test recall: 0.73417723\n",
      "Test precision: 0.6796875\n",
      "Test f1-score: 0.7058823704719543\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential(name='glove_model')\n",
    "model.add(Embedding(input_dim=embeddings_matrix_glove.shape[0],\n",
    "                          output_dim=embeddings_matrix_glove.shape[1],\n",
    "                          weights=[embeddings_matrix_glove],\n",
    "                          input_length=length_long_sentence))\n",
    "model.add(Bidirectional(LSTM(length_long_sentence, return_sequences = True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(length_long_sentence, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(length_long_sentence, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# Take a look at the model summary\n",
    "model.summary()\n",
    "\n",
    "# Define model metrics\n",
    "RECALL = tensorflow.keras.metrics.Recall(name='recall')\n",
    "PRECISION = tensorflow.keras.metrics.Precision(name='precision')\n",
    "METRICS = [RECALL, PRECISION]\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=METRICS)\n",
    "\n",
    "# Fit the model\n",
    "hist = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.3,\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print(\"Test recall:\", score[1])\n",
    "print(\"Test precision:\", score[2])\n",
    "print(\"Test f1-score:\", 2 * ((score[1] * score[2]) / (score[1] + score[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfb40c5",
   "metadata": {},
   "source": [
    "## III. Connection à l'espace Azure<a class=\"anchor\" id=\"III\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15f19b37",
   "metadata": {
    "gather": {
     "logged": 1644961715082
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.37.0\n",
      "Workspace name:Projet-7\n",
      "Azure region:francecentral\n",
      "Resource group:oc-ia-p7\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(\"Workspace name:\" + ws.name,\n",
    "     \"Azure region:\" + ws.location,\n",
    "     \"Resource group:\" + ws.resource_group, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2035280f",
   "metadata": {},
   "source": [
    "## IV. Enregistrement du modèle<a class=\"anchor\" id=\"IV\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c518d45e",
   "metadata": {
    "gather": {
     "logged": 1644961722645
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model sentiment_model\n"
     ]
    }
   ],
   "source": [
    "model.save('sentiment_model/sentiment_model.h5')\n",
    "\n",
    "with open('sentiment_model/tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(word_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "classification_model = Model.register(workspace=ws,\n",
    "                       model_name='sentiment_model',\n",
    "                       model_path='sentiment_model',\n",
    "                       description='A sentiment classification model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dfdc3a",
   "metadata": {},
   "source": [
    "## V. Déploiement du modèle<a class=\"anchor\" id=\"V\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f56ed29b",
   "metadata": {
    "gather": {
     "logged": 1644962044243
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing: compute-model\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-02-15 21:48:46+00:00 Creating Container Registry if not exists.\n",
      "2022-02-15 21:48:46+00:00 Registering the environment.\n",
      "2022-02-15 21:48:48+00:00 Use the existing image.\n",
      "2022-02-15 21:48:48+00:00 Generating deployment configuration.\n",
      "2022-02-15 21:48:53+00:00 Submitting deployment to compute.\n",
      "2022-02-15 21:48:55+00:00 Checking the status of deployment service-aci..\n",
      "2022-02-15 21:53:59+00:00 Checking the status of inference endpoint service-aci.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "compute_target_name = \"compute-model\"\n",
    "compute_target = ComputeTarget(workspace=ws, name=compute_target_name)\n",
    "print(\"Found existing:\", compute_target.name)\n",
    "\n",
    "env = Environment(name=\"env\")\n",
    "\n",
    "conda = CondaDependencies()\n",
    "conda.add_conda_package('scikit-learn')\n",
    "conda.add_conda_package('numpy')\n",
    "conda.add_conda_package('keras')\n",
    "conda.add_conda_package('tensorflow')\n",
    "conda.add_conda_package('tensorflow-gpu')\n",
    "conda.add_conda_package('pyspark')\n",
    "\n",
    "env.python.conda_dependencies=conda \n",
    "\n",
    "inference_config = InferenceConfig(\n",
    "    entry_script=\"score.py\",\n",
    "    environment=env\n",
    ")\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=3)\n",
    "\n",
    "model = ws.models[\"sentiment_model\"]\n",
    "\n",
    "service = Model.deploy(\n",
    "    workspace=ws, \n",
    "    name=\"service-aci\", \n",
    "    models=[model], \n",
    "    inference_config=inference_config, \n",
    "    deployment_config=deployment_config,\n",
    "    deployment_target=compute_target,\n",
    "    overwrite=True,\n",
    ")\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf74d63",
   "metadata": {},
   "source": [
    "## VI. Utilisation du web service<a class=\"anchor\" id=\"VI\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35622c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get web service\n",
    "service = Webservice(workspace=ws, name='service-aci')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "332d088e-5f4e-4202-86cc-f6824da42e67",
   "metadata": {
    "gather": {
     "logged": 1644962045129
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tweet is NEGATIVE with a score of 0.48939430713653564\n",
      "Elapsed time: 0.8393192291259766\n"
     ]
    }
   ],
   "source": [
    "# Test after deployment\n",
    "def get_sentiment_from_tweet(tweet):\n",
    "    # Set environment variables\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    # Provide a text example\n",
    "    data = json.dumps({'text': tweet})\n",
    "\n",
    "    # Call with POST request\n",
    "    response = requests.post(service.scoring_uri, data=data, headers=headers)\n",
    "    response = response.json()\n",
    "\n",
    "    # Print result\n",
    "    print('The tweet is %s' % response[\"label\"])\n",
    "    print('Elapsed time: %s' % response[\"elapsed_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cbfa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentiment_from_tweet('I love the users of this platform')"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
